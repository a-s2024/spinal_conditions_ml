{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77b6cd5-571c-4898-9680-71760e22eeff",
   "metadata": {},
   "source": [
    "| **CLASSIFICATION OF SPINAL CONDITIONS** |\n",
    "|-----------------------------------------|\n",
    "---\n",
    "\n",
    "\n",
    "> **Description:**  \n",
    "> The Support Vector Machine (SVM) classifier will be used to create a model that can tell spinal conditions apart, helping improve diagnosis and treatment for spinal disorders. Accuracy of the model is equal to 81.72 %.\n",
    "\n",
    "---\n",
    "\n",
    "**Name:** Ayesha Siddiqua  \n",
    "**Student ID:** U22103855\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e63e1-84ee-40a4-b13b-4b2e7c2a8b09",
   "metadata": {},
   "source": [
    "### INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e0da6-0f28-49c7-b452-7e67f01d2ad2",
   "metadata": {},
   "source": [
    "The dataset contains:\n",
    "***310 instances** and **6 features** related to spinal health.* \n",
    "\n",
    "#### Features\n",
    "1. *Pelvic Incidence*\n",
    "2. *Pelvic Tilt*\n",
    "3. *Lumbar Lordosis Angle*\n",
    "4. *Sacral Slope*\n",
    "5. *Pelvic Radius*\n",
    "6. *Degree of Spondylolisthesis*\n",
    "   \n",
    "#### Spinal Condition Categories\n",
    "1. *Normal (NO)* - Patients without any spinal issues.\n",
    "2. *Disk Hernia (DH)* - Patients with a herniated disc.\n",
    "3. *Spondylolisthesis (SL)* - Patients with vertebrae that have slipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d0883-9e88-4bbc-aaea-376ec00ea650",
   "metadata": {},
   "source": [
    "### **1. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6bfeb7-1c95-4726-a96d-3064a3bf4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt #simple data visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns #some advanced data visualizations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to get rid of warnings\n",
    "plt.style.use('seaborn-v0_8-white') #defining desired style of viz\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc5742-31db-4670-ba1d-3587ad282377",
   "metadata": {},
   "source": [
    "**Loading the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d990ca-c525-454a-b89f-0b5d797d9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# loading the dataset\n",
    "\n",
    "# read the file into a dataframe \n",
    "df = pd.read_csv('vertebral_column.csv')\n",
    "\n",
    "# display the dataframe to check if it was loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f12be-47e8-46cb-ad49-882fa9bc47cc",
   "metadata": {},
   "source": [
    "**Handling Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff9dbc-70ff-4272-afaf-95858a24d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in the dataframe\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# display the count of missing values for each column\n",
    "print(missing_values)\n",
    "\n",
    "# check if there are any missing values\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"\\nNo missing values.\")\n",
    "else:\n",
    "    print(\"\\nMissing values found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914c6da-9827-413b-b62b-d8d4e70d53d7",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa07c-dfc4-4615-bea8-e86c56769e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES & TARGETS COLUMNS\n",
    "\n",
    "features = df.columns[:-1]  \n",
    "target = df.columns[-1]     \n",
    "\n",
    "# Data preprocessing\n",
    "x = df.iloc[:, :-1].values # feature values\n",
    "y = df.iloc[:, -1].values # target values\n",
    "\n",
    "labels=df[target].unique()\n",
    "\n",
    "# print the names of the features\n",
    "print(\"Features: \\n\", list(features))\n",
    "\n",
    "# print the label type \n",
    "print(\"Labels: \\n\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b928f-63f6-41dc-82d5-15c361295e65",
   "metadata": {},
   "source": [
    "**Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542dc127-b305-4d61-9f39-b9917b5bc7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical labels to numerical values using label encoding:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# TARGET LABELS: Disk Hernia -> 0, Normal -> 1, Spondylolisthesis -> 2.\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19c9ba-1e85-450c-a9ee-085767b14703",
   "metadata": {},
   "source": [
    "**Normalization/Scaling & Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa09a5-4d10-4b8a-8987-3286bbedbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Feature scaling \n",
    "# This ensures equal weight for each feature and improves model performance.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e392bc-3c9f-465d-9d43-625d52489698",
   "metadata": {},
   "source": [
    "**Feature selection using Recursive Feature Elimination (RFE) with SVM classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246eb0d9-7f33-48f7-9938-6d71d7c339f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Print the names of features before RFE\n",
    "print(\"Features before RFE:\")\n",
    "for feature in features:\n",
    "    print(feature)\n",
    "\n",
    "# Feature selection using Recursive Feature Elimination (RFE) with SVM classifier\n",
    "svm = SVC(kernel=\"linear\")\n",
    "rfe_selector = RFE(estimator=svm, n_features_to_select=6, step=1) #choosing 6 features as it gives highest accuracy\n",
    "X_train_rfe = rfe_selector.fit_transform(x_train, y_train)\n",
    "X_test_rfe = rfe_selector.transform(x_test)\n",
    "\n",
    "# Train the SVM classifier on the selected features\n",
    "svm.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test_rfe)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy with selected features:\\n\", accuracy)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_feature_indices = rfe_selector.support_\n",
    "\n",
    "# Get the names of selected features\n",
    "selected_feature_names = features[selected_feature_indices]\n",
    "\n",
    "print(\"\\nSelected Features after RFE:\")\n",
    "for feature in selected_feature_names:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71a093-3015-4dbd-8c4f-d201a5593ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ranking of each feature\n",
    "feature_ranking = rfe_selector.ranking_\n",
    "\n",
    "# Print the rank of each feature\n",
    "print(\"Rank of each feature:\")\n",
    "for feature_name, rank in zip(features, feature_ranking):\n",
    "    print(f\"{feature_name}: {rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d3a5d-5fb5-4be5-a271-e18172ce9a06",
   "metadata": {},
   "source": [
    "### **2. Generating SVM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673c82b-e255-4fe7-aad2-5a0f62f810b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f4008-94c0-466a-92fa-12a70c50b0bb",
   "metadata": {},
   "source": [
    "I used GridSearchCV for tuning hyperparameters.\n",
    "\n",
    "GridSearchCV automatically takes care of cross-validation for all combinations of hyperparameters, so I didn't need to do separate KFold cross-validation by setting the cv parameter to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefba96-82c8-42b6-b207-b1486e0bb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Initialize SVM classifier for multiclass \n",
    "svm = SVC(decision_function_shape='ovo')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "test_accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e4626-091d-441a-9c14-1aca176b56ff",
   "metadata": {},
   "source": [
    "**Choosing Best Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74c6a8-ae98-463a-94a6-ba0812658ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = SVC(kernel=best_params['kernel'], C=best_params['C'], gamma=best_params['gamma'])\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "# Fit the model using the training sets\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict the response for the test dataset\n",
    "y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58777788-28e6-458c-a028-711067a5a6c1",
   "metadata": {},
   "source": [
    "### **3. Evaluating the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc9b07-5b86-47fd-bc00-3e015d252ba9",
   "metadata": {},
   "source": [
    "**ACCURACY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c877e-501e-4c3b-baa6-824c1712a063",
   "metadata": {},
   "source": [
    "- Test size: 0.20 -> Acccuracy: 75.81 %\n",
    "- Test size: 0.25 -> Acccuracy: 80.77 %\n",
    "- Test size: 0.30 -> Acccuracy: 81.72 %\n",
    "\n",
    "**Hence, choosing test size=0.3 as it gives us the highest accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72ffa7-25c9-42c8-8f64-6d73c6a78185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100 \n",
    "print(f'Accuracy of the model is equal to {round(accuracy, 2)} %.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8dcf21-6cc5-4a28-a1dc-2a5c9977de42",
   "metadata": {},
   "source": [
    "**CONFUSION MATRIX, F1 SCORE, PRECISION AND RECALL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a20bce-f8b7-4451-ba52-d70745f78034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, recall_score, precision_score\n",
    "\n",
    "# confusion matrix to summarize the classification results        \n",
    "CM = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", CM)\n",
    "\n",
    "# F1 score - the harmonic mean of precision and recall\n",
    "# 'weighted' averaging is used to consider the proportion of each class in the dataset\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  \n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "        \n",
    "# Recall measures the ability of the model to identify positive instances       \n",
    "recall = recall_score(y_test, y_pred, average='weighted')    \n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Precision measures the accuracy of positive predictions\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Plotting the confusion matrix heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(CM, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "                    xticklabels=['Disk Hernia', 'Normal', 'Spondylolisthesis'], \n",
    "                    yticklabels=['Disk Hernia', 'Normal', 'Spondylolisthesis'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328521e-946c-4812-a612-0a597abe85cc",
   "metadata": {},
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    ")\n",
    "labels = [\"Disk Hernia\", \"Normal\", \"Spondylolisthesis\"]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4e4ed-cc39-442f-b645-87e5c9ba5847",
   "metadata": {},
   "source": [
    "### **4. Saving the trained SVM model as a .pkl file for deployment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083c708-b1da-4e92-9c5f-6717cb5b53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, 'svm_spinal_classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
